---
title: "K Nearest Neighbors"
author: "R.M. Palmer"
date: "11/18/2019"
output: html_document
---

```{r setup_knn, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Predict Attrition with K-nearest-neighbor algorithm.

## Define functions and select predictors

```{r}
library(caret)
library(class)
```

```{r prep_for_knn}
# scale all numeric variables to normalize
# then select only the variable to be predicted and the normalized values
for_knn <- employee_data %>%
  dplyr::select(Attrition,
         z_DistanceFromHome,
         z_Education,
         z_EnvironmentSatisfaction,
         z_JobInvolvement,
         z_JobLevel,
         z_JobSatisfaction,
         z_NumCompaniesWorked,
         z_PercentSalaryHike,
         z_PerformanceRating,
         z_RelationshipSatisfaction,
         z_StockOptionLevel,
         z_TotalWorkingYears,
         z_TrainingTimesLastYear,
         z_WorkLifeBalance,
         z_YearsAtCompany,
         z_YearsInCurrentRole,
         z_YearsSinceLastPromotion,
         z_YearsWithCurrManager)

# selected by stepwise AIC
cols_for_knn <- c("z_DistanceFromHome",
         "z_EnvironmentSatisfaction",
         "z_JobInvolvement",
         "z_JobSatisfaction",
         "z_NumCompaniesWorked",
         "z_RelationshipSatisfaction",
         "z_StockOptionLevel",
         "z_TotalWorkingYears",
         "z_TrainingTimesLastYear",
         "z_WorkLifeBalance",
         "z_YearsInCurrentRole",
         "z_YearsSinceLastPromotion")

## t_DistanceFromHome           1  0.774  0.7743  7.1447 0.0076635 ** 
## t_EnvironmentSatisfaction    1  0.659  0.6592  6.0826 0.0138496 *  
## t_JobInvolvement             1  4.160  4.1601 38.3877 9.047e-10 ***
## t_JobSatisfaction            1  1.608  1.6080 14.8383 0.0001260 ***
## t_NumCompaniesWorked         1  0.363  0.3629  3.3482 0.0676286 .  
## t_RelationshipSatisfaction   1  0.240  0.2404  2.2178 0.1367976    
## t_TotalWorkingYears          1  7.246  7.2460 66.8625 1.061e-15 ***
## t_TrainingTimesLastYear      1  0.514  0.5143  4.7461 0.0296407 *  
## t_WorkLifeBalance            1  0.700  0.6996  6.4557 0.0112374 *  
## t_YearsInCurrentRole         1  0.303  0.3033  2.7986 0.0947135 .  
## t_YearsSinceLastPromotion    1  2.120  2.1203 19.5651 1.099e-05 ***
## BusinessTravel               2  1.501  0.7507  6.9266 0.0010379 ** 
## JobRole                      8  3.082  0.3852  3.5546 0.0004615 ***
## MaritalStatus                2  2.517  1.2586 11.6139 1.057e-05 ***

# adjust the knn results by known probabilities
knn_adjust <- function(orig_factor, k, num_no=1, num_yes=1)
{
  # original probabilities
  orig_win    <- attr(orig_factor,'prob')
  orig_lose   <- 1.0 - orig_win
  
  # What was original answer
  orig_answer <- as.character(orig_factor)
  other_answer <- ifelse(orig_answer == 'No','Yes','No')
  
  win_votes <- k * orig_win
  lose_votes <- k - win_votes
  
  # if the original answer was no, then divide win by total number of no's
  #win  <- win_votes  / ifelse (orig_answer == 'No', num_no, num_yes)
  win <- win_votes
  
  # if the original answer was yes, then divide lose by total number of no's
  #lose <- lose_votes / ifelse (orig_answer == 'Yes',num_no,num_yes)
  lose <- lose_votes
  
  # alter the answer if lose > win
  new_answer <- as.factor(ifelse( (lose > win), other_answer, orig_answer))
  
  levels(new_answer) <- levels(orig_factor)
  return(new_answer)
}

         
```

## What is the expected outcome?

```{r knn_start}
summary(for_knn$Attrition)
```

```{r knn_sanity}
truth <- dplyr::count(employee_data,vars=Attrition)
truth.yes <- as.numeric(truth[2,2])
truth.no  <- as.numeric(truth[1,2])
truth.nobs <- truth.yes + truth.no
true_yes_perc <- round(100*truth.yes/truth.nobs)
true_no_perc  <- round(100*truth.no/truth.nobs)
```

True percentage of "yes" values is `r true_yes_perc`  
True percentage of "no"  values is `r true_no_perc` 

## Set parameters for KNN

```{r knn_parms}
set.seed(42)
train_frac <- 0.7
numks <- 50
# knn_trials <- 250
knn_trials <- 100
positive_value <- 'Yes'
```

## Select K

run KNN with different values of K to select appropriate neighborhood size.

```{r do_knn}
# look for the best value of k
#  do 100 trials, and for each trial
#   split data into training and test
#   make classifier and from the confusion matrix,
#   save the accuracy, sensitivity, and specificity
knn_stats = matrix(nrow=numks,ncol=6)
for (i in 1:numks)
{
  acc  = matrix(nrow=knn_trials,ncol=1)
  sens = matrix(nrow=knn_trials,ncol=1)
  spec = matrix(nrow=knn_trials,ncol=1)
  pcyes = matrix(nrow=knn_trials,ncol=1)
  pcno  = matrix(nrow=knn_trials,ncol=1)
  for (j in 1:knn_trials)
  {
    trainIndices = sample(1:dim(for_knn)[1],round(train_frac * dim(for_knn)[1]))
    trainData = for_knn[trainIndices,]
    testData = for_knn[-trainIndices,]
    raw_class = knn(trainData[,cols_for_knn],
                              testData[,cols_for_knn],
                              trainData$Attrition, prob = TRUE, k = i)
    classifications = knn_adjust(raw_class, k = i, num_no = , num_yes = )
    tmp <- data.frame(classifications)
    answers <- count(tmp,vars=classifications)
    num_yes <- as.numeric(answers[2,2])
    num_no  <- as.numeric(answers[1,2])
    num_obs <- num_yes + num_no

    CM = confusionMatrix(table(testData$Attrition,classifications),positive=positive_value)
    acc[j]  = CM$overall[1]
    sens[j] = CM$byClass[1]
    spec[j] = CM$byClass[2]
    pcyes[j] = num_yes / num_obs
    pcno[j]  = num_no / num_obs
  }
  
  # make a matrix with accuracy, sensitivity, and specificity
  knn_stats[i,1] = i
  knn_stats[i,2] = colMeans(acc,na.rm = TRUE)
  knn_stats[i,3] = colMeans(sens,na.rm = TRUE)
  knn_stats[i,4] = colMeans(spec,na.rm = TRUE)
  knn_stats[i,5] = colMeans(pcyes,na.rm = TRUE)
  knn_stats[i,6] = colMeans(pcno,na.rm = TRUE)
}

```

```{r plot_k_stats}
stats_frame <- data.frame(knn_stats)
colnames(stats_frame) <- c("k","accuracy","sensitivity","specificity","Perc_Yes","Perc_No")
for_plot <- reshape2::melt(stats_frame,id.var='k')
for_plot %>% ggplot(aes(x=k,y=value,col=variable)) + 
  geom_line() +
  xlab('k') +
  ylab('percent') +
  ggtitle('Performance of Classifier by K')
```

```{r choose_k}
combined_stats <- stats_frame %>% 
  mutate(sums = accuracy + sensitivity + specificity) 

max_acc_k <- which.max(knn_stats[,2])

chosen_k = max_acc_k

chosen_acc  <- round(100*combined_stats$accuracy[chosen_k])
chosen_sens <- round(100*combined_stats$sensitivity[chosen_k])
chosen_spec <- round(100*combined_stats$specificity[chosen_k])
```

## Select K

max accuracy is at k = `r max_acc_k`.  

We choose `r chosen_k` to go forward in constructing a classifier, since
this provides the highest accuracy.

That value of k, on our train and test split, gives and average accuracy of `r chosen_acc`, an average sensitivity of `r chosen_sens` and a specificity of `r chosen_spec`.

## Repeat classificaiton on entire dataset

```{r knn_eval}
# make a new classifier using all the data
knn_pred <- knn(for_knn[,cols_for_knn],
                for_knn[,cols_for_knn],
                for_knn$Attrition,k=chosen_k)
CM_knn = confusionMatrix(table(as.factor(for_knn$Attrition),knn_pred),positive=positive_value)
knn_acc <- CM_knn$overall[1] # accuracy
knn_sens <- CM_knn$byClass[1] # sensitivity
knn_spec <- CM_knn$byClass[2] # specificity

tmp <- data.frame(knn_pred)
answers <- count(tmp,vars=knn_pred)
num_yes <- as.numeric(answers[2,2])
num_no  <- as.numeric(answers[1,2])
num_obs <- num_yes + num_no
perc_yes <- round(100*num_yes/num_obs)
perc_no  <- round(100*num_no/num_obs)
```

Using the entire dataset,

KNN accuracy turns out to be `r format(100*knn_acc,digits=2)` %.

KNN sensitivity is `r format(100*knn_sens,digits=2)` %.

KNN specificity is `r format(100*knn_spec,digits=2)` %.

## Predict with KNN

Since the KNN classifier does a better job of predicting Attrition, we will
use it for making predictions on the unlabeled data for submission.

```{r knn_pred}
# read in the blind test dataset

blind_raw <- read.csv('CaseStudy2CompSetNoAttrition.csv')
blind_test <- my_transform(blind_raw)
predicted_attrition <- as.factor(knn(for_knn[,cols_for_knn],
                           blind_test[,cols_for_knn],
                           for_knn$Attrition,k=chosen_k))
levels(predicted_attrition) <- c("No","Yes")
summary(predicted_attrition)
for_submission <- cbind(blind_test$ID,as.factor(predicted_attrition))
colnames(for_submission) <- c("ID","Attrition")
write.csv(for_submission,file="Case2PredictionsPalmerAttrition.csv",row.names=FALSE)
```